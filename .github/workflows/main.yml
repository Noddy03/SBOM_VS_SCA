name: Fetch Top IoT Repositories + Trivy/Conan SBOM Scan (Full NTIA + BSI V2 Compliance)

on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language to scan (e.g. C++, Python, Java)"
        required: true
        default: "C++"

permissions:
  contents: read
  security-events: write
  actions: read

jobs:
  fetch_top_repos:
    name: Fetch top 50 IoT GitHub repositories (${{ github.event.inputs.language }})
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.fetch.outputs.repo_list }}
    steps:
      - name: Install tools
        run: |
          sudo apt-get update && sudo apt-get install -y jq curl
      - name: Fetch top 50 IoT repositories
        id: fetch
        env:
          LANG: ${{ github.event.inputs.language }}
        run: |
          echo "Fetching top 50 IoT-related repositories written in $LANG..."
          REPOS=$(gh api /search/repositories \
            --method GET \
            -F q="IoT language:$LANG fork:false archived:false" \
            -F sort=stars -F order=desc -F per_page=50 \
            --jq '.items[].full_name' || true)
          JSON_ARRAY=$(echo "$REPOS" | jq -R -s -c 'split("\n")[:-1]')
          echo "repo_list=$JSON_ARRAY" >> "$GITHUB_OUTPUT"

  sbom_scan:
    name: SBOM Scan + Enrichment + NTIA/BSI V2 Compliance
    needs: fetch_top_repos
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJSON(needs.fetch_top_repos.outputs.repo_list) }}
    continue-on-error: true

    steps:
      - name: Setup environments
        run: |
          sudo apt-get update
          sudo apt-get install -y jq uuid-runtime python3-pip coreutils curl
          pip install --no-cache-dir conan cyclonedx-bom

      - name: Checkout repository
        id: checkout
        continue-on-error: true
        uses: actions/checkout@v4
        with:
          repository: ${{ matrix.repo }}
          path: project-src
          fetch-depth: 0
          token: ${{ secrets.MY_PERSONAL_TOKEN || github.token }}

      - name: Conan setup
        if: steps.checkout.outcome == 'success'
        run: |
          conan profile detect --force

      - name: Run Trivy SBOM scan
        if: steps.checkout.outcome == 'success'
        continue-on-error: true
        uses: aquasecurity/trivy-action@0.25.0
        with:
          scan-type: fs
          scan-ref: ./project-src
          format: cyclonedx
          scanners: vuln
          output: project-src/trivy-report.json
          ignore-unfixed: true
          vuln-type: os,library
          severity: CRITICAL,HIGH,MEDIUM
          timeout: 10m

      - name: Check SBOM existence
        id: sbom_exists
        run: |
          FILE="project-src/trivy-report.json"
          if [ -f "$FILE" ]; then
            echo "sbom_exists=true" >> "$GITHUB_OUTPUT"
          else
            echo "sbom_exists=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Generate CycloneDX Dependency SBOM
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          cyclonedx-bom -o project-src/deps.bom.json -e -i ./project-src || echo "âš ï¸ cyclonedx-bom failed or produced no BOM."

      - name: Merge Trivy SBOM with Dependency SBOM (safe)
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          SBOM="project-src/trivy-report.json"
          DEPS="project-src/deps.bom.json"
          OUT="project-src/merged-sbom.json"

          if [ ! -s "$DEPS" ]; then
            echo "âš ï¸ No deps.bom.json found; skipping merge."
            exit 0
          fi

          if ! jq empty "$SBOM" "$DEPS" 2>/dev/null; then
            echo "âŒ One or both SBOM files invalid; skipping merge."
            exit 0
          fi

          echo "ðŸ”„ Merging BOM..."
          jq -s '.[0] * .[1]' "$SBOM" "$DEPS" > "$OUT"
          mv "$OUT" "$SBOM"

      - name: Enrich SBOM metadata and components
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          FILE="project-src/trivy-report.json"
          SUPPLIER="${{ matrix.repo }}"
          SUPPLIER="${SUPPLIER%%/*}"
          VCS_URL="https://github.com/${{ matrix.repo }}"
          VERSION=$(git -C project-src describe --tags --always 2>/dev/null || echo "unknown")
          HASH=$(git -C project-src rev-parse HEAD 2>/dev/null || echo "unknown")

          jq --arg supplier "$SUPPLIER" \
             --arg version "$VERSION" \
             --arg vcs "$VCS_URL" \
             --arg hash "$HASH" \
          '
          if (.components | type) == "array" then
            .components |= map(
              .supplier = { "name": $supplier } |
              .version = ($version) |
              .properties += [
                {"name": "source_code_uri", "value": $vcs},
                {"name": "source_hash", "value": $hash}
              ] |
              .licenses = (.licenses // [{"license": {"id": "NOASSERTION"}}]) |
              .externalReferences += [{"type": "vcs", "url": $vcs}]
            )
          else
            .
          end |
          .metadata.properties += [
            {"name": "build_system", "value": "GitHub Actions"},
            {"name": "sbom_dependencies", "value": (if (.dependencies // []) | length > 0 then "true" else "false" end)}
          ]
          ' "$FILE" > project-src/tmp_enriched.json && mv project-src/tmp_enriched.json "$FILE"

      - name: Inject SHA-256 for source files (safe)
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          FILE="project-src/trivy-report.json"
          TMP="project-src/tmp_hash_inject.json"
          cp "$FILE" "$TMP"

          echo "ðŸ” Injecting file hashes..."
          find project-src -type f \( -name "*.c" -o -name "*.cpp" -o -name "*.h" -o -name "*.py" -o -name "*.jar" -o -name "*.so" \) | head -n 100 | \
          while read -r SRC; do
            HASH=$(sha256sum "$SRC" | awk '{print $1}')
            REL_PATH=$(realpath --relative-to=project-src "$SRC" || echo "$SRC")

            jq --arg rel "$REL_PATH" --arg h "$HASH" '
              (.components // []) |= map(
                if (.externalReferences // [] | map(.url // "") | any(. == $rel; .)) then
                  .properties += [{"name": "file_hash", "value": $h}]
                else
                  .
                end
              )
            ' "$TMP" > project-src/tmp_hash.json && mv project-src/tmp_hash.json "$TMP"
          done

          mv "$TMP" "$FILE"
          echo "ðŸŸ¢ File hash injection done."

      - name: NTIA Compliance Check
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          docker run --rm -v "$PWD/project-src":/project-src ghcr.io/interlynk-io/sbomqs:latest compliance --ntia /project-src/trivy-report.json > project-src/compliance_NTIA.json

      - name: BSI V2 Compliance Check
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          docker run --rm -v "$PWD/project-src":/project-src ghcr.io/interlynk-io/sbomqs:latest compliance --bsi-v2 /project-src/trivy-report.json > project-src/compliance_BSI.json

      - name: Score SBOM
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          docker run --rm -v "$PWD/project-src":/project-src ghcr.io/interlynk-io/sbomqs:latest score /project-src/trivy-report.json --json > project-src/score_evaluation.json

      - name: Sanitize artifact name
        id: sanitize
        run: |
          SAFE_NAME="${{ matrix.repo }}"
          SAFE_NAME="${SAFE_NAME//\//_}"
          echo "name=$SAFE_NAME" >> "$GITHUB_OUTPUT"

      - name: Upload SBOM reports
        uses: actions/upload-artifact@v4
        with:
          name: sbom-reports-${{ steps.sanitize.outputs.name }}
          path: project-src/*.json
          if-no-files-found: warn

  aggregate_results:
    name: Aggregate SBOMQS Results
    needs: sbom_scan
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results/
        
      - name: Install Python + Pandas
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip
          pip install --no-cache-dir pandas

      - name: Aggregate SBOMQS JSON results
        run: |
          python3 <<'PY'
          import json, glob, pandas as pd, os

          def load_json_safe(path):
              try:
                  with open(path) as f:
                      return json.load(f)
              except:
                  return None

          records = []
          for path in glob.glob("results/**/score_evaluation.json", recursive=True):
              repo = os.path.basename(os.path.dirname(path))
              data = load_json_safe(path)
              if data: 
                  data['repository'] = repo
                  records.append(data)

          for std in ["BSI", "NTIA"]:
              for path in glob.glob(f"results/**/compliance_{std}.json", recursive=True):
                  repo = os.path.basename(os.path.dirname(path))
                  data = load_json_safe(path)
                  if data:
                      data['repository'] = repo
                      data['standard'] = std
                      records.append(data)

          if records:
              df = pd.json_normalize(records)
              df.to_csv("sbomqs_summary.csv", index=False)
              print("Summary generated successfully")
          else:
              print("No valid SBOMQS data found.")
          PY

      - name: Upload Summary Report
        uses: actions/upload-artifact@v4
        with:
          name: sbomqs-summary
          path: sbomqs_summary.csv
