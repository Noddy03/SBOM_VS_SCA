name: Fetch Top IoT Repositories + Trivy/Conan SBOM Scan (Full NTIA + BSI V2 Compliance)

on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language to scan (e.g. C++, Python, Java)"
        required: true
        default: "C++"

permissions:
  contents: read
  security-events: write
  actions: read

jobs:
  # ---------------------------------------------------------
  # 1. FETCH TOP IoT REPOSITORIES
  # ---------------------------------------------------------
  fetch_top_repos:
    name: Fetch top 50 IoT GitHub repositories (${{
      github.event.inputs.language}})
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.fetch.outputs.repo_list }}
    steps:
      - name: Install jq and gh
        run: |
          sudo apt-get update
          sudo apt-get install -y jq curl

      - name: Fetch top 50 IoT repositories
        id: fetch
        env:
          LANG: ${{ github.event.inputs.language }}
          GH_TOKEN: ${{ github.token }}
        run: |
          echo "ðŸ” Fetching top 50 IoT repositories in $LANG..."
          REPOS=$(gh api "/search/repositories" \
            --method GET \
            -F q="IoT in:name,description language:$LANG" \
            -F sort=stars \
            -F order=desc \
            -F per_page=50 \
            -q '.items[].full_name' || true)

          JSON_ARRAY=$(echo "$REPOS" | jq -R -s -c 'split("\n")[:-1]')
          echo "ðŸ“¦ Found $(echo "$JSON_ARRAY" | jq 'length') repositories."
          echo "repo_list=$JSON_ARRAY" >> "$GITHUB_OUTPUT"

  # ---------------------------------------------------------
  # SBOM PROCESSING JOB
  # ---------------------------------------------------------
  sbom_scan:
    name: SBOM Scan + Enrichment + NTIA/BSI V2 Compliance
    needs: fetch_top_repos
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJSON(needs.fetch_top_repos.outputs.repo_list) }}
    continue-on-error: true

    steps:
      - name: Setup environments
        run: |
          sudo apt-get update
          sudo apt-get install -y jq uuid-runtime python3-pip coreutils curl
          pip install --no-cache-dir conan cyclonedx-bom

      - name: Checkout repository
        id: checkout
        continue-on-error: true
        uses: actions/checkout@v4
        with:
          repository: ${{ matrix.repo }}
          path: project-src
          fetch-depth: 0
          token: ${{ github.token }}

      - name: Conan setup
        if: steps.checkout.outcome == 'success'
        run: |
          conan profile detect --force || true

      - name: Run Trivy SBOM scan
        if: steps.checkout.outcome == 'success'
        uses: aquasecurity/trivy-action@0.25.0
        with:
          scan-type: fs
          scan-ref: ./project-src
          format: cyclonedx
          scanners: vuln
          output: project-src/trivy-report.json
          ignore-unfixed: true
          vuln-type: os,library
          severity: CRITICAL,HIGH,MEDIUM

      - name: Check SBOM existence
        id: sbom_exists
        run: |
          [ -f "project-src/trivy-report.json" ] && echo "sbom_exists=true" >> "$GITHUB_OUTPUT" || echo "sbom_exists=false" >> "$GITHUB_OUTPUT"

      - name: Generate CycloneDX Dependency SBOM
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: cyclonedx-bom -o project-src/deps.bom.json -e -i ./project-src || true

      - name: Merge Trivy SBOM with Dependency SBOM
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          SBOM="project-src/trivy-report.json"
          DEPS="project-src/deps.bom.json"

          if [ -s "$DEPS" ]; then
            jq -s '.[0] * .[1]' "$SBOM" "$DEPS" > project-src/merged-sbom.json
            mv project-src/merged-sbom.json "$SBOM"
            echo "ðŸ”„ SBOMs merged."
          else
            echo "âš ï¸ No dependency SBOM to merge."
          fi

      - name: Enrich SBOM metadata and components
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          SBOM="project-src/trivy-report.json"
          SUPPLIER="${{ matrix.repo }}"
          SUPPLIER="${SUPPLIER%%/*}"
          VCS_URL="https://github.com/${{ matrix.repo }}"
          VERSION=$(git -C project-src describe --tags --always 2>/dev/null || echo "unknown")
          HASH=$(git -C project-src rev-parse HEAD 2>/dev/null || echo "unknown")

          jq --arg supplier "$SUPPLIER" \
             --arg version "$VERSION" \
             --arg vcs "$VCS_URL" \
             --arg hash "$HASH" \
          '
          .components |= map(
            .supplier = {"name": $supplier} |
            .version = $version |
            .licenses = (.licenses // [{"license": {"id": "NOASSERTION"}}]) |
            .properties += [{"name":"source_code_uri","value":$vcs},{"name":"source_hash","value":$hash}]
          ) |
          .metadata.properties += [
            {"name":"sbom_build_system","value":"GitHub Actions"},
            {"name":"sbom_dependencies","value":(.dependencies | length > 0 | tostring)}
          ]' "$SBOM" > project-src/enriched-sbom.json && mv project-src/enriched-sbom.json "$SBOM"

      - name: Inject SHA-256 for source files (safe)
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: |
          SBOM="project-src/trivy-report.json"
          TMP="project-src/temp_sbom.json"
          cp "$SBOM" "$TMP"

          find project-src -type f | head -n 100 | while read -r SRC; do
            HASH=$(sha256sum "$SRC" | awk '{print $1}')
            REL_PATH=$(realpath --relative-to=project-src "$SRC" || echo "$SRC")

            jq --arg rel "$REL_PATH" --arg h "$HASH" '
              .components |= map(
                if (.properties // [] | map(.name) | index("file_hash")) then .
                else .properties += [{"name":"file_hash","value":$h}]
                end
              )
            ' "$TMP" > project-src/tmp2.json && mv project-src/tmp2.json "$TMP"
          done

          mv "$TMP" "$SBOM"

      - name: NTIA Compliance Check
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: docker run --rm -v "$PWD/project-src":/project-src ghcr.io/interlynk-io/sbomqs:latest compliance --ntia /project-src/trivy-report.json > project-src/compliance_NTIA.json

      - name: BSI V2 Compliance Check
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: docker run --rm -v "$PWD/project-src":/project-src ghcr.io/interlynk-io/sbomqs:latest compliance --bsi-v2 /project-src/trivy-report.json > project-src/compliance_BSI.json

      - name: Score SBOM
        if: steps.sbom_exists.outputs.sbom_exists == 'true'
        run: docker run --rm -v "$PWD/project-src":/project-src ghcr.io/interlynk-io/sbomqs:latest score /project-src/trivy-report.json --json > project-src/score_evaluation.json

      - name: Sanitize artifact name
        id: sanitize
        run: |
          NAME="${{ matrix.repo }}"
          echo "name=${NAME//\//_}" >> "$GITHUB_OUTPUT"

      - name: Upload SBOM reports
        uses: actions/upload-artifact@v4
        with:
          name: sbom-reports-${{ steps.sanitize.outputs.name }}
          path: project-src/*.json
          if-no-files-found: warn

  # ---------------------------------------------------------
  # 3. AGGREGATE RESULTS
  # ---------------------------------------------------------
  aggregate_results:
    name: Aggregate SBOMQS Results
    needs: sbom_scan
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results/

      - name: Install Python + Pandas
        run: |
          sudo apt-get update && sudo apt-get install -y python3-pip
          pip install pandas

      - name: Aggregate SBOMQS JSON results
        run: |
          python3 <<'EOF'
          import json, glob, pandas as pd, os

          def load_json(path):
              try:
                  with open(path) as f:
                      return json.load(f)
              except:
                  return None

          rows = []
          for f in glob.glob("results/**/score_evaluation.json", recursive=True):
              data = load_json(f)
              if not data: continue
              repo = f.split("/")[-2]
              data["repo"] = repo
              rows.append(data)

          df = pd.json_normalize(rows)
          df.to_csv("sbomqs_summary.csv", index=False)
          EOF

      - name: Upload Summary
        uses: actions/upload-artifact@v4
        with:
          name: sbomqs-summary
          path: sbomqs_summary.csv
