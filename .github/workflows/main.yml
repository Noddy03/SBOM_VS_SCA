name: Fetch Top IoT Repositories + Trivy/Conan SBOM Scan (NTIA + BSI V2)

# Trigger
on:
  workflow_dispatch:
    inputs:
      language:
        description: "Programming language to scan (C++, Python, Java, etc.)"
        required: true
        default: "C++"

# Minimal permissions required
permissions:
  contents: read
  security-events: write
  actions: read

jobs:
  # ================================================================
  # 1. FETCH TOP REPOS  (UNCHANGED â€” DO NOT TOUCH)
  # ================================================================
  fetch_top_repos:
    runs-on: ubuntu-latest
    outputs:
      repo_list: ${{ steps.fetch.outputs.repo_list }}

    steps:
      - name: Install jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq

      - name: Fetch repositories  # <--- DO NOT TOUCH (AS REQUESTED)
        id: fetch
        env:
          LANG: ${{ github.event.inputs.language }}
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          RAW_Q="topic:IoT language:$LANG fork:false archived:false"
          echo "Query: $RAW_Q"
          REPOS=$(gh api -X GET /search/repositories \
             --raw-field q="$RAW_Q" \
             --raw-field sort=stars \
             --raw-field order=desc \
             --raw-field per_page=50 \
             --jq '.items[].full_name'
          )
          echo "Found repos:"
          echo "$REPOS"
          JSON_ARRAY=$(printf "%s\n" "$REPOS" | jq -R -s -c 'split("\n")[:-1]')
          echo "repo_list=$JSON_ARRAY" >> $GITHUB_OUTPUT

  # ================================================================
  # 2. SBOM SCAN + ENRICHMENT (YAML A - full)
  # ================================================================
  sbom_scan:
    needs: fetch_top_repos
    runs-on: ubuntu-latest
    continue-on-error: true

    strategy:
      fail-fast: false
      matrix:
        repo: ${{ fromJSON(needs.fetch_top_repos.outputs.repo_list) }}

    steps:
      # ------------------------------------------------------------
      # Install required tools: conan, jq, trivy
      # ------------------------------------------------------------
      - name: Install Conan + jq + Trivy
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq wget curl python3-pip
          pip install --upgrade pip
          pip install conan
          # Install trivy (adds trivy executable to /usr/local/bin)
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh \
            | sudo sh -s -- -b /usr/local/bin

      # ------------------------------------------------------------
      # Checkout repository (shallow clone) - skip if cannot clone
      # ------------------------------------------------------------
      - name: Checkout repository
        env:
          REPO: ${{ matrix.repo }}
          TOKEN: ${{ secrets.MY_PERSONAL_TOKEN || github.token }}
        run: |
          set -euo pipefail
          if git clone --depth=1 "https://$TOKEN@github.com/$REPO" project-src; then
              echo "skip_repo=false" >> $GITHUB_ENV
          else
              echo "skip_repo=true" >> $GITHUB_ENV
          fi

      # --------------------------------------------------------------------
      # 2A â€” GITHUB LICENSE API (best-effort)
      # Use Accept header and fallback to NOASSERTION
      # --------------------------------------------------------------------
      - name: Fetch GitHub license metadata
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail
          # Preferred Accept header; fall back to NOASSERTION on error/404
          gh api -H "Accept: application/vnd.github+json" "/repos/$REPO/license" > project-src/gh-license.json 2>/dev/null \
            || echo '{"license":{"spdx_id":"NOASSERTION"}}' > project-src/gh-license.json

      # --------------------------------------------------------------------
      # 2B â€” LOCAL LICENSE DETECTION (fallback)
      # Detect common license filenames (LICENSE, COPYING, etc.)
      # --------------------------------------------------------------------
      - name: Local license file detection (fallback)
        if: env.skip_repo != 'true'
        run: |
          set -euo pipefail
          echo "ðŸ”Ž Searching for local license files..."
          FILE=$(find project-src -maxdepth 4 -type f \
            -iregex ".*\(LICENSE\|LICENCE\|COPYING\|COPYRIGHT\|LICENSE\.md\|LICENSE\.txt\)" \
            | head -1 || true)
          if [ -n "$FILE" ]; then
            echo "ðŸ“„ Found local license file: $FILE"
            cp "$FILE" project-src/local-license.txt
          else
            echo "âš ï¸ No local license file found."
            echo "" > project-src/local-license.txt
          fi

      # --------------------------------------------------------------------
      # 2C â€” BUILD SBOMs (Conan + Trivy)
      # Conan for dependency info (if present), Trivy for CycloneDX SBOM
      # --------------------------------------------------------------------
      - name: Conan SBOM
        if: env.skip_repo != 'true'
        run: |
          set -euo pipefail
          cd project-src || exit 1
          conan profile detect --force || true
          conan graph info . --format=json > conan-sbom.json || echo '{"components":[]}' > conan-sbom.json

      - name: Trivy SBOM (CycloneDX)
        if: env.skip_repo != 'true'
        run: |
          set -euo pipefail
          # Generate CycloneDX SBOM from filesystem
          trivy fs --scanners vuln,license --format cyclonedx \
            -o project-src/trivy-fs.json project-src \
            || echo '{"components":[]}' > project-src/trivy-fs.json

      # --------------------------------------------------------------------
      # 2D â€” MERGE LICENSE SIGNALS (GitHub -> Trivy -> Local -> NOASSERTION)
      # Guarantees metadata.licenses and per-component licenses
      # --------------------------------------------------------------------
      - name: Merge GitHub + Trivy + Local license into SBOM
        if: env.skip_repo != 'true'
        run: |
          set -euo pipefail
          SBOM="project-src/trivy-fs.json"
          GHLIC="project-src/gh-license.json"
          LOCALLIC="project-src/local-license.txt"

          # Extract SPDX from GitHub / Trivy
          GH_SPDX=$(jq -r '.license.spdx_id // empty' "$GHLIC" 2>/dev/null || echo "")
          TRIVY_SPDX=$(jq -r '
            [.components[]?.licenses[]?.license?.id // empty] |
            map(select(. != "")) | unique | join(",")
          ' "$SBOM" 2>/dev/null || echo "")

          LOCAL_SPDX=""
          if [ -s "$LOCALLIC" ]; then LOCAL_SPDX="CUSTOM"; fi

          if [ -n "$GH_SPDX" ] && [ "$GH_SPDX" != "NOASSERTION" ]; then
            FINAL="$GH_SPDX"
          elif [ -n "$TRIVY_SPDX" ]; then
            FINAL="$TRIVY_SPDX"
          elif [ -n "$LOCAL_SPDX" ]; then
            FINAL="$LOCAL_SPDX"
          else
            FINAL="NOASSERTION"
          fi

          # Ensure SBOM exists
          if [ ! -f "$SBOM" ] || [ ! -s "$SBOM" ]; then
            echo '{"bomFormat":"CycloneDX","components":[],"metadata":{}}' > "$SBOM"
          fi

          # Inject merged license into metadata and components where missing
          jq --arg lic "$FINAL" '
            .metadata.licenses = [{ "license": { "id": $lic }}] |
            .components |= map(
              if (.licenses | length) == 0 then .licenses = [{ "license": { "id": $lic }}] else . end
            )
          ' "$SBOM" > tmp.json && mv tmp.json "$SBOM"

      # --------------------------------------------------------------------
      # 2E â€” ENRICH SBOM FOR NTIA + BSI V2 (component-level, robust jq)
      # Adds: component.supplier, component.hashes (SBOM-level), externalReferences, metadata.bomLinks,
      # metadata.tools/properties, signature, timestamp.
      # --------------------------------------------------------------------
      - name: Enrich SBOM for NTIA + BSI v2 (component-level)
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
        run: |
          set -euo pipefail
          SBOM="project-src/trivy-fs.json"
          REPO_URL="https://github.com/$REPO"
          OWNER=$(echo "$REPO" | cut -d'/' -f1)

          # Ensure SBOM file exists and is valid JSON
          if [ ! -f "$SBOM" ] || [ ! -s "$SBOM" ]; then
            echo '{"bomFormat":"CycloneDX","components":[],"metadata":{}}' > "$SBOM"
          fi

          # Compute SBOM-level SHA256 signature (fast Option 1)
          FULL_SHA=$(sha256sum "$SBOM" | awk '{print $1}')
          echo "SBOM SHA256: $FULL_SHA"

          # Robust jq transformation ensuring no object+array add errors:
          # normalize metadata arrays then add the required fields and per-component entries
          jq --arg owner "$OWNER" --arg repo "$REPO" --arg repourl "$REPO_URL" --arg sha "$FULL_SHA" '
            # Normalize metadata arrays (if objects -> wrap in array; if missing -> empty array)
            .metadata.tools |= (if type=="object" then [.] elif type=="array" then . else [] end) |
            .metadata.properties |= (if type=="object" then [.] elif type=="array" then . else [] end) |
            .metadata.bomLinks |= (if type=="object" then [.] elif type=="array" then . else [] end) |
            .metadata.externalReferences |= (if type=="object" then [.] elif type=="array" then . else [] end) |

            # Add/merge tool info and build metadata
            .metadata.tools += [{
              "vendor": "Aqua Security",
              "name": "Trivy",
              "version": "CycloneDX"
            }] |
            .metadata.properties += [
              {"name":"build.environment","value":"GitHub Actions (ubuntu-latest)"},
              {"name":"build.timestamp","value":(now|todate)}
            ] |

            # Supplier metadata at SBOM level (still add per-component below)
            .metadata.supplier = {
              "name": $owner,
              "url": ("https://github.com/" + $owner)
            } |

            # Add or append bomLinks
            .metadata.bomLinks += [
              {"rel":"self","href":("https://github.com/" + $repo + "/sbom")},
              {"rel":"repository","href": $repourl},
              {"rel":"distribution","href": ($repourl + "/releases")}
            ] |

            # Signature block (simple SBOM-level signature using computed sha)
            .signature = {"algorithm":"SHA-256","value":$sha} |

            # Ensure components exists as array
            .components |= (if . == null then [] else . end) |

            # Per-component enrichment: supplier, hashes, externalReferences, ensure license presence
            .components |= map(
              (. // {}) |
              .supplier = (.supplier // {"name": $owner, "url": ("https://github.com/" + $owner)}) |
              .hashes = (if (.hashes // []) | length == 0 then [{"alg":"SHA-256","content":$sha}] else .hashes end) |
              .externalReferences = ((.externalReferences // []) + [
                {"type":"vcs","url": $repourl},
                {"type":"distribution","url": ($repourl + "/releases")}
              ]) |
              .licenses = (if (.licenses // []) | length == 0 then [{ "license": { "id": "NOASSERTION" }}] else .licenses end)
            )
          ' "$SBOM" > tmp.json && mv tmp.json "$SBOM"

          echo "âœ” Enrichment complete: component.supplier, component.hashes, externalReferences, metadata, bomLinks, signature inserted."

      # --------------------------------------------------------------------
      # 2F â€” SBOMQS COMPLIANCE ANALYSIS (NTIA + BSI) and Score with creation_info injection
      # We make sure these steps always produce JSON (fallback to {}), then inject creation_info into score.json
      # --------------------------------------------------------------------
      - name: NTIA Compliance
        if: env.skip_repo != 'true'
        run: |
          set -euo pipefail
          # Run compliance NTIA; if it fails, write empty JSON so aggregator can still run
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --ntia /sbom/trivy-fs.json \
            > project-src/compliance_NTIA.json || echo '{}' > project-src/compliance_NTIA.json

      - name: BSI v2 Compliance
        if: env.skip_repo != 'true'
        run: |
          set -euo pipefail
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            compliance --bsi-v2 /sbom/trivy-fs.json \
            > project-src/compliance_BSI.json || echo '{}' > project-src/compliance_BSI.json

      - name: Score SBOM (with creation_info injection)
        if: env.skip_repo != 'true'
        env:
          REPO: ${{ matrix.repo }}
        run: |
          set -euo pipefail
          # Run score; fallback to empty JSON if the container errors
          docker run --rm -v $PWD/project-src:/sbom ghcr.io/interlynk-io/sbomqs:latest \
            score /sbom/trivy-fs.json --json \
            > project-src/score.json || echo '{}' > project-src/score.json

          # Inject creation_info block so aggregator can extract the expected columns.
          # creation_info fields: name, version, scoring_engine_version, vendor
          # We preserve any existing scoring_engine_version if present in the output.
          jq --arg repo "$REPO" '
            .creation_info = {
              "name": "SBOMQS Score",
              "version": "1.0",
              "scoring_engine_version": (.scoring_engine_version // "unknown"),
              "vendor": $repo
            }
          ' project-src/score.json > project-src/score.tmp.json && mv project-src/score.tmp.json project-src/score.json

      # --------------------------------------------------------------------
      # 2G â€” Packaging / Upload artifacts (unchanged behaviour)
      # --------------------------------------------------------------------
      - name: Sanitize artifact name
        id: sanitize
        run: |
          set -euo pipefail
          SAFE="${{ matrix.repo }}"
          SAFE="${SAFE//\//_}"
          echo "name=$SAFE" >> $GITHUB_OUTPUT

      - name: Upload SBOM reports
        uses: actions/upload-artifact@v4
        with:
          name: sbom-reports-${{ steps.sanitize.outputs.name }}
          path: project-src/*.json
          if-no-files-found: warn

  # ================================================================
  # 3. AGGREGATION SUMMARY â€” FIX MODE A (produce compact summary CSV)
  # ================================================================
  aggregate_results:
    name: Aggregate SBOMQS Results
    needs: sbom_scan
    runs-on: ubuntu-latest

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: results/

      - name: Install Python + Pandas
        run: |
          sudo apt-get update && sudo apt-get install -y python3-pip
          pip install pandas

      - name: Aggregate into sbomqs_summary.csv (minimal layout)
        run: |
          python3 <<'EOF'
          import json, glob, os, pandas as pd, time

          def load_json_safe(p):
              try:
                  with open(p) as f:
                      return json.load(f)
              except Exception:
                  return None

          rows = []
          run_id = os.getenv("GITHUB_RUN_ID", "")
          timestamp = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())

          # Find artifact directories that contain score.json
          score_paths = glob.glob("results/**/score.json", recursive=True)
          # Normalize list of artifact dirs (dir that contains each score.json)
          artifact_dirs = sorted({ os.path.dirname(p) for p in score_paths })

          for ad in artifact_dirs:
              # repository: try to get the artifact folder name (often 'sbom-reports_<repo>')
              repo = os.path.basename(ad)
              # find first score.json under this artifact dir (may be nested)
              score_list = glob.glob(os.path.join(ad, "**", "score.json"), recursive=True)
              score_data = None
              if score_list:
                  score_data = load_json_safe(score_list[0])

              # count presence of relevant files (score + compliance_NTIA + compliance_BSI)
              files_count = 0
              if glob.glob(os.path.join(ad, "**", "score.json"), recursive=True):
                  files_count += 1
              if glob.glob(os.path.join(ad, "**", "compliance_NTIA.json"), recursive=True):
                  files_count += 1
              if glob.glob(os.path.join(ad, "**", "compliance_BSI.json"), recursive=True):
                  files_count += 1

              # Extract creation_info fields from score.json (injected earlier)
              ci = {}
              if isinstance(score_data, dict):
                  ci = score_data.get("creation_info", {}) or {}

              row = {
                  "run_id": run_id,
                  "timestamp": timestamp,
                  "files": files_count,
                  "repository": repo,
                  "creation_info.name": ci.get("name", ""),
                  "creation_info.version": ci.get("version", ""),
                  "creation_info.scoring_engine_version": ci.get("scoring_engine_version", ""),
                  "creation_info.vendor": ci.get("vendor", "")
              }
              rows.append(row)

          if rows:
              df = pd.DataFrame(rows)
              df.to_csv("sbomqs_summary.csv", index=False)
              print("Generated sbomqs_summary.csv with", len(rows), "rows")
          else:
              print("No score.json files found; sbomqs_summary.csv not created")
          EOF

      - name: Upload aggregated summary
        uses: actions/upload-artifact@v4
        with:
          name: sbomqs-summary
          path: sbomqs_summary.csv
